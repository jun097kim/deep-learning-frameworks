{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(x) = W·x + b\n",
    "\n",
    "# 우리가 학습할 X, Y 데이터가 주어짐\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# W, b는 Variable 노드로 정의할 수 있음\n",
    "# [1]: rank가 1인 1차원 array\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "\n",
    "- TensorFlow가 사용하는 variable\n",
    "- TensorFlow를 실행시키면 TensorFlow가 자체적으로 변경시키는 값\n",
    "- trainable한 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "# reduce_mean: 어떤 Tensor가 주어졌을 때 그것을 평균내어 주는 것\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost) # 무엇을 minimize할 것인가?\n",
    "# 우리가 선언했던 tf.Variable을 조정해서 알아서 minimize하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9777797 [1.4220507] [0.51936036]\n",
      "20 0.02801536 [0.93468505] [0.2892847]\n",
      "40 0.00941193 [0.89323664] [0.2561059]\n",
      "60 0.008402714 [0.89401513] [0.24220516]\n",
      "80 0.0076301503 [0.8985925] [0.23064484]\n",
      "100 0.006929818 [0.9033198] [0.21978845]\n",
      "120 0.006293768 [0.90785974] [0.20945759]\n",
      "140 0.0057160943 [0.9121896] [0.19961374]\n",
      "160 0.005191458 [0.91631633] [0.19023262]\n",
      "180 0.0047149607 [0.9202492] [0.18129236]\n",
      "200 0.0042822086 [0.92399716] [0.17277224]\n",
      "220 0.0038891707 [0.927569] [0.1646526]\n",
      "240 0.0035322078 [0.93097305] [0.15691455]\n",
      "260 0.0032079946 [0.9342171] [0.14954008]\n",
      "280 0.0029135551 [0.9373086] [0.14251223]\n",
      "300 0.002646146 [0.94025487] [0.13581473]\n",
      "320 0.0024032663 [0.9430627] [0.12943192]\n",
      "340 0.0021826832 [0.94573855] [0.12334908]\n",
      "360 0.0019823525 [0.9482887] [0.11755213]\n",
      "380 0.0018003974 [0.95071894] [0.11202754]\n",
      "400 0.0016351524 [0.9530349] [0.10676267]\n",
      "420 0.001485074 [0.9552421] [0.10174521]\n",
      "440 0.0013487685 [0.9573455] [0.09696358]\n",
      "460 0.0012249727 [0.95935005] [0.09240671]\n",
      "480 0.0011125399 [0.96126056] [0.08806393]\n",
      "500 0.0010104222 [0.9630812] [0.08392522]\n",
      "520 0.00091768353 [0.9648162] [0.07998104]\n",
      "540 0.00083345856 [0.9664697] [0.07622221]\n",
      "560 0.0007569595 [0.9680455] [0.07264005]\n",
      "580 0.0006874842 [0.96954715] [0.06922626]\n",
      "600 0.0006243835 [0.97097844] [0.0659729]\n",
      "620 0.0005670751 [0.9723424] [0.06287239]\n",
      "640 0.00051502336 [0.9736422] [0.05991762]\n",
      "660 0.00046775318 [0.9748808] [0.05710172]\n",
      "680 0.00042482364 [0.97606134] [0.05441816]\n",
      "700 0.00038583056 [0.9771864] [0.05186071]\n",
      "720 0.00035041888 [0.9782585] [0.04942346]\n",
      "740 0.00031825618 [0.97928035] [0.04710075]\n",
      "760 0.00028904225 [0.9802542] [0.04488711]\n",
      "780 0.00026251088 [0.98118216] [0.04277753]\n",
      "800 0.000238418 [0.9820665] [0.04076712]\n",
      "820 0.0002165328 [0.9829093] [0.0388512]\n",
      "840 0.00019666023 [0.9837125] [0.03702533]\n",
      "860 0.00017861153 [0.98447794] [0.03528525]\n",
      "880 0.00016221631 [0.98520744] [0.03362696]\n",
      "900 0.00014732774 [0.9859026] [0.03204662]\n",
      "920 0.00013380614 [0.9865651] [0.03054055]\n",
      "940 0.00012152407 [0.98719656] [0.02910526]\n",
      "960 0.00011036999 [0.9877982] [0.02773742]\n",
      "980 0.00010023933 [0.9883717] [0.02643388]\n",
      "1000 9.103999e-05 [0.9889181] [0.02519159]\n",
      "1020 8.268412e-05 [0.9894389] [0.02400771]\n",
      "1040 7.5094176e-05 [0.9899354] [0.02287942]\n",
      "1060 6.820267e-05 [0.99040836] [0.02180414]\n",
      "1080 6.1942315e-05 [0.9908591] [0.02077941]\n",
      "1100 5.625689e-05 [0.9912887] [0.01980283]\n",
      "1120 5.1092797e-05 [0.99169815] [0.01887214]\n",
      "1140 4.6403733e-05 [0.9920883] [0.0179852]\n",
      "1160 4.21445e-05 [0.99246013] [0.01713995]\n",
      "1180 3.8276226e-05 [0.9928144] [0.01633443]\n",
      "1200 3.4762368e-05 [0.9931522] [0.01556678]\n",
      "1220 3.1571955e-05 [0.993474] [0.01483517]\n",
      "1240 2.8673778e-05 [0.9937807] [0.01413796]\n",
      "1260 2.6042662e-05 [0.994073] [0.01347354]\n",
      "1280 2.365229e-05 [0.9943515] [0.01284033]\n",
      "1300 2.1481785e-05 [0.9946169] [0.01223691]\n",
      "1320 1.951021e-05 [0.9948699] [0.01166182]\n",
      "1340 1.7718558e-05 [0.9951111] [0.01111377]\n",
      "1360 1.6092397e-05 [0.9953408] [0.01059143]\n",
      "1380 1.4615386e-05 [0.9955598] [0.01009367]\n",
      "1400 1.3274261e-05 [0.9957684] [0.00961929]\n",
      "1420 1.2055993e-05 [0.99596727] [0.00916724]\n",
      "1440 1.0949443e-05 [0.99615675] [0.00873645]\n",
      "1460 9.944682e-06 [0.9963374] [0.0083259]\n",
      "1480 9.032049e-06 [0.9965095] [0.00793462]\n",
      "1500 8.20309e-06 [0.9966735] [0.00756174]\n",
      "1520 7.449948e-06 [0.99682987] [0.00720637]\n",
      "1540 6.7659007e-06 [0.9969789] [0.00686771]\n",
      "1560 6.1450423e-06 [0.99712086] [0.00654495]\n",
      "1580 5.581425e-06 [0.99725616] [0.00623736]\n",
      "1600 5.0686544e-06 [0.9973851] [0.00594424]\n",
      "1620 4.6038244e-06 [0.997508] [0.00566491]\n",
      "1640 4.1812295e-06 [0.9976251] [0.00539869]\n",
      "1660 3.7973016e-06 [0.9977367] [0.00514496]\n",
      "1680 3.448983e-06 [0.997843] [0.0049032]\n",
      "1700 3.1324323e-06 [0.9979444] [0.00467277]\n",
      "1720 2.8449713e-06 [0.99804103] [0.00445317]\n",
      "1740 2.5838199e-06 [0.99813306] [0.0042439]\n",
      "1760 2.3467958e-06 [0.9982208] [0.00404448]\n",
      "1780 2.1311828e-06 [0.9983044] [0.0038544]\n",
      "1800 1.9355905e-06 [0.9983841] [0.00367328]\n",
      "1820 1.7580351e-06 [0.99846005] [0.00350065]\n",
      "1840 1.596604e-06 [0.9985324] [0.00333614]\n",
      "1860 1.4500516e-06 [0.99860144] [0.00317936]\n",
      "1880 1.317037e-06 [0.9986671] [0.00302995]\n",
      "1900 1.1962323e-06 [0.9987297] [0.00288757]\n",
      "1920 1.0864105e-06 [0.99878937] [0.00275191]\n",
      "1940 9.86705e-07 [0.9988463] [0.0026226]\n",
      "1960 8.9606664e-07 [0.99890053] [0.00249937]\n",
      "1980 8.1395314e-07 [0.99895215] [0.00238192]\n",
      "2000 7.392736e-07 [0.9990014] [0.00227001]\n"
     ]
    }
   ],
   "source": [
    "# 세션 실행\n",
    "sess = tf.Session()\n",
    "# Variable을 사용해서 실행하기 전에는\n",
    "# 반드시 tf.global_variables_initializer를 실행시켜 주어야 함\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)  # train 노드 실행\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
